{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5a04dc",
   "metadata": {},
   "source": [
    "# Simple CNN example for classificaiton\n",
    "\n",
    "Let's see how we can build a super simple CNN classifier for images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5acc9",
   "metadata": {},
   "source": [
    "## 1. Open the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc31b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_folder = \"dataset\"\n",
    "\n",
    "# Training data folder\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "# Test data folder\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13d76a",
   "metadata": {},
   "source": [
    "## 2. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bb1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling model\n",
    "model.compile(\n",
    "    # Choose the loss function\n",
    "    loss='binary_crossentropy',\n",
    "    # Choose your optimizer\n",
    "    optimizer=RMSprop(learning_rate=1e-4),\n",
    "    # Choose the metric the model will use to evaluate his learning\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0483a7c",
   "metadata": {},
   "source": [
    "## 3. Preprocess images\n",
    "### A) Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fda429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # This is the source directory for training images    \n",
    "    train_dir,\n",
    "    # All images will be resized to 150x150\n",
    "    target_size=(150, 150),  \n",
    "    # Define how big are gonna be your batch.\n",
    "    batch_size=20,\n",
    "    # Since we use binary_crossentropy loss, we need binary labels\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59495193",
   "metadata": {},
   "source": [
    "### B) Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1de30c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645c07a",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3734ec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is detected by tensorflow\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba7954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 11s 75ms/step - loss: 0.6856 - accuracy: 0.5510 - val_loss: 0.6572 - val_accuracy: 0.6290\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.6528 - accuracy: 0.6195 - val_loss: 0.6285 - val_accuracy: 0.6550\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.6089 - accuracy: 0.6635 - val_loss: 0.6007 - val_accuracy: 0.6840\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.5664 - accuracy: 0.7140 - val_loss: 0.5919 - val_accuracy: 0.6860\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.5357 - accuracy: 0.7355 - val_loss: 0.5752 - val_accuracy: 0.6970\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.5138 - accuracy: 0.7410 - val_loss: 0.5588 - val_accuracy: 0.7010\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.4866 - accuracy: 0.7730 - val_loss: 0.5463 - val_accuracy: 0.7220\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.4698 - accuracy: 0.7765 - val_loss: 0.5485 - val_accuracy: 0.7180\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.4415 - accuracy: 0.7970 - val_loss: 0.5775 - val_accuracy: 0.7150\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.4181 - accuracy: 0.7980 - val_loss: 0.5608 - val_accuracy: 0.7370\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.3852 - accuracy: 0.8280 - val_loss: 0.5586 - val_accuracy: 0.7230\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.3679 - accuracy: 0.8395 - val_loss: 0.6050 - val_accuracy: 0.7160\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.3475 - accuracy: 0.8565 - val_loss: 0.5396 - val_accuracy: 0.7470\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.3218 - accuracy: 0.8650 - val_loss: 0.5407 - val_accuracy: 0.7530\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.3007 - accuracy: 0.8780 - val_loss: 0.5605 - val_accuracy: 0.7470\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.2716 - accuracy: 0.8980 - val_loss: 0.5693 - val_accuracy: 0.7470\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.2567 - accuracy: 0.8985 - val_loss: 0.5475 - val_accuracy: 0.7550\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.2314 - accuracy: 0.9095 - val_loss: 0.5999 - val_accuracy: 0.7510\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.2170 - accuracy: 0.9230 - val_loss: 0.6510 - val_accuracy: 0.7320\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.1994 - accuracy: 0.9285 - val_loss: 0.6090 - val_accuracy: 0.7530\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1796 - accuracy: 0.9425 - val_loss: 0.6171 - val_accuracy: 0.7410\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.1591 - accuracy: 0.9410 - val_loss: 0.6065 - val_accuracy: 0.7640\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.1465 - accuracy: 0.9490 - val_loss: 0.6435 - val_accuracy: 0.7520\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.1230 - accuracy: 0.9625 - val_loss: 0.6557 - val_accuracy: 0.7720\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.1123 - accuracy: 0.9635 - val_loss: 0.6751 - val_accuracy: 0.7570\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.1014 - accuracy: 0.9710 - val_loss: 0.6875 - val_accuracy: 0.7570\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.0869 - accuracy: 0.9745 - val_loss: 0.7613 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0789 - accuracy: 0.9770 - val_loss: 0.7798 - val_accuracy: 0.7460\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0640 - accuracy: 0.9855 - val_loss: 0.7922 - val_accuracy: 0.7680\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0568 - accuracy: 0.9840 - val_loss: 0.8108 - val_accuracy: 0.7670\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0493 - accuracy: 0.9880 - val_loss: 0.8400 - val_accuracy: 0.7640\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.8415 - val_accuracy: 0.7510\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.0370 - accuracy: 0.9910 - val_loss: 0.8433 - val_accuracy: 0.7610\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0333 - accuracy: 0.9905 - val_loss: 0.9069 - val_accuracy: 0.7640\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.9847 - val_accuracy: 0.7620\n",
      "Epoch 36/50\n",
      " 53/100 [==============>...............] - ETA: 1s - loss: 0.0203 - accuracy: 0.9953"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    # 2000 images = batch_size * steps\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    # 1000 images = batch_size * steps\n",
    "    validation_steps=50,  \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af2cad",
   "metadata": {},
   "source": [
    "## 5. Vizualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
